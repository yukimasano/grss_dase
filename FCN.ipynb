{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "os.environ['MKL_NUM_THREADS'] = \"8\"\n",
    "os.environ['OMP_NUM_THREADS'] = \"8\"\n",
    "OMP_NUM_THREADS=8\n",
    "MKL_NUM_THREADS=8\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(2)\n",
    "\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathToData = 'data/rit18.mat'\n",
    "mat_contents = sio.loadmat(pathToData)\n",
    "\n",
    "train_data = mat_contents['train_data'].astype('int16',casting ='same_kind')\n",
    "train_labels = mat_contents['train_labels'].astype('int16',casting ='same_kind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN32s(nn.Module):\n",
    "    def __init__(self, n_class=21):\n",
    "        super(FCN32s, self).__init__()\n",
    "        # conv1\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
    "\n",
    "        # conv2\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
    "\n",
    "        # conv3\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
    "\n",
    "        # conv4\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
    "\n",
    "        # conv5\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
    "\n",
    "        # fc6\n",
    "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.drop6 = nn.Dropout2d()\n",
    "\n",
    "        # fc7\n",
    "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.drop7 = nn.Dropout2d()\n",
    "\n",
    "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
    "        self.upscore = nn.ConvTranspose2d(n_class, n_class, 64, stride=32,\n",
    "                                          bias=False)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.zero_()\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                assert m.kernel_size[0] == m.kernel_size[1]\n",
    "                initial_weight = get_upsampling_weight(\n",
    "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
    "                m.weight.data.copy_(initial_weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.relu1_1(self.conv1_1(h))\n",
    "        h = self.relu1_2(self.conv1_2(h))\n",
    "        h = self.pool1(h)\n",
    "\n",
    "        h = self.relu2_1(self.conv2_1(h))\n",
    "        h = self.relu2_2(self.conv2_2(h))\n",
    "        h = self.pool2(h)\n",
    "\n",
    "        h = self.relu3_1(self.conv3_1(h))\n",
    "        h = self.relu3_2(self.conv3_2(h))\n",
    "        h = self.relu3_3(self.conv3_3(h))\n",
    "        h = self.pool3(h)\n",
    "\n",
    "        h = self.relu4_1(self.conv4_1(h))\n",
    "        h = self.relu4_2(self.conv4_2(h))\n",
    "        h = self.relu4_3(self.conv4_3(h))\n",
    "        h = self.pool4(h)\n",
    "\n",
    "        h = self.relu5_1(self.conv5_1(h))\n",
    "        h = self.relu5_2(self.conv5_2(h))\n",
    "        h = self.relu5_3(self.conv5_3(h))\n",
    "        h = self.pool5(h)\n",
    "\n",
    "        h = self.relu6(self.fc6(h))\n",
    "        h = self.drop6(h)\n",
    "\n",
    "        h = self.relu7(self.fc7(h))\n",
    "        h = self.drop7(h)\n",
    "\n",
    "        h = self.score_fr(h)\n",
    "\n",
    "        h = self.upscore(h)\n",
    "        h = h[:, :, 19:19 + x.size()[2], 19:19 + x.size()[3]].contiguous()\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def copy_params_from_vgg16(self, vgg16):\n",
    "        features = [\n",
    "            self.conv1_1, self.relu1_1,\n",
    "            self.conv1_2, self.relu1_2,\n",
    "            self.pool1,\n",
    "            self.conv2_1, self.relu2_1,\n",
    "            self.conv2_2, self.relu2_2,\n",
    "            self.pool2,\n",
    "            self.conv3_1, self.relu3_1,\n",
    "            self.conv3_2, self.relu3_2,\n",
    "            self.conv3_3, self.relu3_3,\n",
    "            self.pool3,\n",
    "            self.conv4_1, self.relu4_1,\n",
    "            self.conv4_2, self.relu4_2,\n",
    "            self.conv4_3, self.relu4_3,\n",
    "            self.pool4,\n",
    "            self.conv5_1, self.relu5_1,\n",
    "            self.conv5_2, self.relu5_2,\n",
    "            self.conv5_3, self.relu5_3,\n",
    "            self.pool5,\n",
    "        ]\n",
    "        for l1, l2 in zip(vgg16.features, features):\n",
    "            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n",
    "                assert l1.weight.size() == l2.weight.size()\n",
    "                assert l1.bias.size() == l2.bias.size()\n",
    "                l2.weight.data = l1.weight.data\n",
    "                l2.bias.data = l1.bias.data\n",
    "        for i, name in zip([0, 3], ['fc6', 'fc7']):\n",
    "            l1 = vgg16.classifier[i]\n",
    "            l2 = getattr(self, name)\n",
    "            l2.weight.data = l1.weight.data.view(l2.weight.size())\n",
    "            l2.bias.data = l1.bias.data.view(l2.bias.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
    "    \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
    "                      dtype=np.float64)\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return torch.from_numpy(weight).float()\n",
    "\n",
    "def get_parameters(model, bias=False):\n",
    "    modules_skipped = (\n",
    "        nn.ReLU,\n",
    "        nn.MaxPool2d,\n",
    "        nn.Dropout2d,\n",
    "        nn.Sequential,\n",
    "        FCN32s,\n",
    "    )\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            if bias:\n",
    "                yield m.bias\n",
    "            else:\n",
    "                yield m.weight\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            # weight is frozen because it is just a bilinear upsampling\n",
    "            if bias:\n",
    "                assert m.bias is None\n",
    "        elif isinstance(m, modules_skipped):\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError('Unexpected module: %s' % str(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(1337)\n",
    "\n",
    "# 1. dataset\n",
    "cuda= False\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "train_loader = ''\n",
    "val_loader = ''\n",
    "# 2. model\n",
    "\n",
    "model = FCN32s(n_class=21)\n",
    "start_epoch = 0\n",
    "start_iteration = 0\n",
    "\n",
    "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "model.copy_params_from_vgg16(vgg16)\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# 3. optimizer\n",
    "cfg = dict(\n",
    "        max_iteration=100000,\n",
    "        lr=1.0e-14,\n",
    "        momentum=0.99,\n",
    "        weight_decay=0.0005,\n",
    "        interval_validate=4000,\n",
    "        fcn16s_pretrained_model='',\n",
    ")\n",
    "optim = torch.optim.SGD(\n",
    "    [\n",
    "        {'params': get_parameters(model, bias=False)},\n",
    "        {'params': get_parameters(model, bias=True),\n",
    "         'lr': cfg['lr'] * 2, 'weight_decay': 0},\n",
    "    ],\n",
    "    lr=cfg['lr'],\n",
    "    momentum=cfg['momentum'],\n",
    "    weight_decay=cfg['weight_decay'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy2d(input, target, weight=None, size_average=True):\n",
    "    # input: (n, c, h, w), target: (n, h, w)\n",
    "    n, c, h, w = input.size()\n",
    "    # log_p: (n, c, h, w)\n",
    "    if LooseVersion(torch.__version__) < LooseVersion('0.3'):\n",
    "        # ==0.2.X\n",
    "        log_p = F.log_softmax(input)\n",
    "    else:\n",
    "        # >=0.3\n",
    "        log_p = F.log_softmax(input, dim=1)\n",
    "    # log_p: (n*h*w, c)\n",
    "    log_p = log_p.transpose(1, 2).transpose(2, 3).contiguous()\n",
    "    log_p = log_p[target.view(n, h, w, 1).repeat(1, 1, 1, c) >= 0]\n",
    "    log_p = log_p.view(-1, c)\n",
    "    # target: (n*h*w,)\n",
    "    mask = target >= 0\n",
    "    target = target[mask]\n",
    "    loss = F.nll_loss(log_p, target, weight=weight, size_average=False)\n",
    "    if size_average:\n",
    "        loss /= mask.data.sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                                            | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-eca29d7aa6b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     for batch_idx, (data, target) in tqdm.tqdm(\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             desc='Train epoch=%d' % epoch, ncols=80, leave=False):\n\u001b[1;32m      9\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "max_epoch = 200\n",
    "size_average=False\n",
    "n_class = 21\n",
    "\n",
    "interval_validate = 4000\n",
    "\n",
    "for epoch in tqdm.trange(0, max_epoch, desc='Train', ncols=80):\n",
    "    for batch_idx, (data, target) in tqdm.tqdm(\n",
    "            enumerate(train_loader), total=len(train_loader),\n",
    "            desc='Train epoch=%d' % epoch, ncols=80, leave=False):\n",
    "        iteration = batch_idx + epoch * len(train_loader)\n",
    "\n",
    "        if iteration % interval_validate == 0:\n",
    "            validate()\n",
    "\n",
    "\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optim.zero_grad()\n",
    "        score = model(data)\n",
    "\n",
    "        loss = cross_entropy2d(score, target,\n",
    "                               size_average=size_average)\n",
    "        loss /= len(data)\n",
    "        if np.isnan(float(loss.data[0])):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "        metrics = []\n",
    "        lbl_pred = score.data.max(1)[1].cpu().numpy()[:, :, :]\n",
    "        lbl_true = target.data.cpu().numpy()\n",
    "        \n",
    "        acc, acc_cls, mean_iu, fwavacc = \\\n",
    "            torchfcn.utils.label_accuracy_score(\n",
    "                lbl_true, lbl_pred, n_class=n_class)\n",
    "            \n",
    "        metrics.append((acc, acc_cls, mean_iu, fwavacc))\n",
    "        metrics = np.mean(metrics, axis=0)\n",
    "\n",
    "#         with open(osp.join(self.out, 'log.csv'), 'a') as f:\n",
    "#             elapsed_time = (\n",
    "#                 datetime.datetime.now(pytz.timezone('Europe/London')) -\n",
    "#                 self.timestamp_start).total_seconds()\n",
    "#             log = [epoch, iteration] + [loss.data[0]] + \\\n",
    "#                 metrics.tolist() + [''] * 5 + [elapsed_time]\n",
    "#             log = map(str, log)\n",
    "#             f.write(','.join(log) + '\\n')\n",
    "\n",
    "        if iteration >= max_iter:\n",
    "            break\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
